# coding=utf-8
# Copyright 2018 The DisentanglementLib Authors.  All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This file contains an exemplary configuration for the dlib_reason script.
#
# This should be configured to match the model that one likes to train. Options
# coresponding to the original paper include:
#
# 'AdamOptimizer.learning_rate' -> 1e-2, 1e-3, or 1e-4
# 'OptimizedWildRelNet.dropout_in_last_graph_layer' -> 0.25, 0.5, 0.75, or None
# 'OptimizedWildRelNet.graph_mlp' -> [256], [128], [128, 128], or [256, 256]
# 'OptimizedWildRelNet.edge_mlp'-> [512, 512, 512, 512], [512, 512, 512],
#                                  [512, 512], [256, 256, 256, 256],
#                                  [256, 256, 256], or [256, 256]
# 'TwoStageModel.embedding_model_class'-> 'onehot', 'values',
#                                         @BaselineCNNEmbedder, or @HubEmbedding
#
# If @HubEmbedding is used, the representation to be used has to be specified
# using the input_dir flag in dlib_reason (e.g., "{path}/postprocessed/mean/"
# where {path} is the output directory of a dlib_reproduce run).
abstract_reasoning.model = @TwoStageModel()
abstract_reasoning.num_iterations = 100
abstract_reasoning.training_steps_per_iteration = 1000
abstract_reasoning.eval_steps_per_iteration = 100
abstract_reasoning.random_seed=0
abstract_reasoning.batch_size = 32
AdamOptimizer.beta1 = 0.9
AdamOptimizer.beta2 = 0.999
AdamOptimizer.epsilon = 1e-8
AdamOptimizer.name = 'Adam'
AdamOptimizer.use_locking = False
TwoStageModel.reasoning_model_class = @OptimizedWildRelNet
BaselineCNNEmbedder.num_latent = 10
OptimizedWildRelNet.edge_mlp = [512, 512, 512, 512]
OptimizedWildRelNet.graph_mlp = [256, 256]
OptimizedWildRelNet.dropout_in_last_graph_layer = 0.5
