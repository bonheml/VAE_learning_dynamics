import logging
import hydra
import numpy as np
import pandas as pd
from hydra.utils import instantiate
from omegaconf import OmegaConf

from vae_ld.learning_dynamics.intrinsic_dimension_estimators import TwoNN, MLE

logger = logging.getLogger("get_data_ide")


def estimate_id(dataset, ides, n_batches, n_samples, seed, normalized=True):
    res = {k: [] for k in ides.keys()}

    for i in range(0, n_batches):
        logger.info("Iteration {}/{}: sampling {} images".format(i+1, n_batches, n_samples))
        X = dataset.sample(n_samples, seed)[1]
        X = np.unique(X.reshape(X.shape[0], np.prod(X.shape[1:])), axis=0)
        if normalized is False:
            X *= 255.
        logger.info("Discarding duplicate examples. Final size is {}".format(len(X)))
        for name, ide in ides.items():
            res[name].append(ide.fit_transform(X))
            logger.info("{} estimate is {}".format(name, res[name][-1]))
    return res


@hydra.main(config_path="config", config_name="data_ide")
def get_all_ides(cfg):
    seed = np.random.RandomState(cfg.seed)
    logger.info("Model config:\n{}".format(OmegaConf.to_yaml(cfg)))
    ides = {"MLE_{}".format(k): MLE(k, seed, anchor=cfg.mle_anchor) for k in [3, 5, 10, 20]}
    ides["TwoNN"] = TwoNN()

    logger.info("Loading {}".format(cfg.dataset.name))
    dataset = instantiate(cfg.dataset)
    res = estimate_id(dataset, ides, cfg.n_iter, cfg.n_samples, seed, cfg.normalized)

    logger.info("Saving the results to {}".format(cfg.save_file))
    df = pd.DataFrame.from_dict(res)
    df.to_csv(cfg.save_file, sep="\t")


if __name__ == "__main__":
    get_all_ides()
