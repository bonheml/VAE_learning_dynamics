import logging

import hydra
import numpy as np
import pandas as pd
from hydra.utils import instantiate
from omegaconf import OmegaConf

from vae_ld.learning_dynamics.intrinsic_dimension_estimators import TwoNN, MLE

logger = logging.getLogger("get_data_ide")


def estimate_id(dataset, ides, n_batches, n_samples):
    res = {k: [] for k in ides.keys()}

    for i in range(0, n_batches * n_samples, n_samples):
        logger.info("Retrieving data examples from index {} to {}".format(i, i + n_samples))
        X = dataset[i:i + n_samples]
        X = np.unique(X.reshape(X.shape[0], np.prod(X.shape[1:])), axis=0)
        logger.info("Discarding duplicate examples. Final size is {}".format(len(X)))

        for name, ide in ides.items():
            res[name].append(ide.fit_transform(X))
            logger.info("{} estimate is {}".format(name, res[name][-1]))

    return res


@hydra.main(config_path="config/data_ide", config_name="config")
def get_all_ides(cfg):
    res = {}
    seed = np.random.RandomState(cfg.seed)
    logger.info("Model config:\n{}".format(OmegaConf.to_yaml(cfg)))
    ides = {"MLE_{}".format(k): MLE(k, seed, anchor=cfg.mle_anchor) for k in [3, 5, 10, 20]}
    ides["TwoNN"] = TwoNN()

    for k, v in cfg.dataset.items():
        logger.info("Loading {}".format(k))
        dataset = instantiate(v)
        n_batches = min(dataset.data_size // cfg.n_samples, cfg.n_iter)
        res[k] = estimate_id(dataset, ides, n_batches, cfg.n_samples)
    reform = {(k1, k2): v2 for k1, v1 in res.items() for k2, v2 in v1.items()}

    logger.info("Saving the results to {}".format(cfg.save_file))
    df = pd.DataFrame.from_dict(reform, orient='index').transpose()
    df.columns = pd.MultiIndex.from_tuples(df.columns)
    df.to_csv(cfg.save_file, sep="\t")


if __name__ == "__main__":
    get_all_ides()
