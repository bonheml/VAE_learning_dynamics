#!/usr/bin/env python
import logging
import hydra
import numpy as np
from hydra.utils import instantiate
from omegaconf import OmegaConf
from glob import glob
from vae_ld.data.util import natural_sort
import tensorflow as tf
from sklearn.metrics import accuracy_score
import pandas as pd

logger = logging.getLogger("downstream_task")


def generate_train_test_sampler(sampler):
    train_sampler = sampler()
    test_sampler = sampler()
    test_sampler.validation = True
    test_sampler.validation_idxs = train_sampler.validation_idxs
    test_sampler.train_idxs = None
    test_sampler.labels = 1
    train_sampler.labels = 1
    test_sampler.categorical = False
    train_sampler.categorical = False
    train_sampler.validation_idxs = None
    return train_sampler, test_sampler


def dt_classify(clf, X_train, y_train, X_test, y_test):
    res = {"train_accuracy": [], "test_accuracy": []}
    for i in range(len(y_train[0])):
        clf = clf.fit(X_train, y_train[:, i])
        y_train_pred = clf.predict(X_train)
        y_test_pred = clf.predict(X_test)
        res["train_accuracy"].append(accuracy_score(y_train[:, i], y_train_pred))
        res["test_accuracy"].append(accuracy_score(y_test[:, i], y_test_pred))
        logger.info(res)
    return res


def get_data(sampler, encoder, n_items, batch_size):
    X, y = None, None
    for i, (X_tmp, y_tmp) in enumerate(sampler):
        X_tmp = encoder(X_tmp)[-3].numpy()
        X = X_tmp if i == 0 else np.vstack((X, X_tmp))
        y = y_tmp if i == 0 else np.vstack((y, y_tmp))
    return X, y


@hydra.main(config_path="config", config_name="downstream_task")
def evaluate_on_downstream_tasks(cfg):
    logger.info("Experiment config:\n{}".format(OmegaConf.to_yaml(cfg)))
    logger.info("Retrieving the data...")
    # We create a partial instantiation first to share the same dataset between samplers
    sampler = instantiate(cfg.sampling, _partial_=True)
    train_sampler, test_sampler = generate_train_test_sampler(sampler)

    logger.info("Loading model from {}".format(cfg.model_path))
    file = sorted(glob(cfg.model_path), key=natural_sort)[-1]
    encoder = tf.keras.models.load_model(file).encoder
    encoder.trainable = False

    logger.info("Instantiating the classifier")
    clf = instantiate(cfg.classifier.clf)

    logger.info("Sampling the data")
    X_train, y_train = get_data(train_sampler, encoder, cfg.num_train, cfg.batch_size)
    X_test, y_test = get_data(test_sampler, encoder, cfg.num_test, cfg.batch_size)

    logger.info("Training the classifier")
    res = dt_classify(clf, X_train, y_train, X_test, y_test)

    logger.info("The scores obtained are {}".format(res))
    df = pd.DataFrame.from_dict(res)
    df.to_csv(cfg.save_file)


if __name__ == "__main__":
    evaluate_on_downstream_tasks()
