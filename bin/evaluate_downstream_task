#!/usr/bin/env python
import logging
import hydra
from hydra.utils import instantiate
from omegaconf import OmegaConf
from glob import glob
from vae_ld.data.util import natural_sort
import tensorflow as tf
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.metrics import f1_score, mean_squared_error
import pandas as pd

logger = logging.getLogger("downstream_task")


@hydra.main(config_path="config", config_name="downstream_task")
def evaluate_on_downstream_tasks(cfg):
    logger.info("Experiment config:\n{}".format(OmegaConf.to_yaml(cfg)))

    logger.info("Retrieving the data...")
    # We create a partial instantiation first to share the same dataset between samplers
    sampler = instantiate(cfg.sampling, _partial_=True)
    logger.debug("The partial sampler is {}".format(sampler))
    train_sampler = sampler()
    logger.debug("The train sampler is {}".format(train_sampler))
    test_sampler = sampler()
    logger.debug("The test sampler is {}".format(test_sampler))
    # We update the test_sampler with the validation indexes from the train sampler
    test_sampler.validation = True
    test_sampler.validation_idxs = train_sampler.validation_idxs
    # Remove unused index list to avoid unneeded memory usage
    test_sampler.train_idxs = None
    train_sampler.validation_idxs = None

    logger.info("Loading model from {}".format(cfg.model_path))
    file = sorted(glob(cfg.model_path), key=natural_sort)[-1]
    encoder = tf.keras.models.load_model(file).encoder

    logger.info("Retrieving compressed representations")
    Z_train = encoder.predict(train_sampler, batch_size=cfg.batch_size)
    logger.info(Z_train.shape)
    Z_test = encoder.predict(test_sampler, batch_size=cfg.batch_size)
    Y_train = train_sampler.data.index.index_to_features(train_sampler.train_idxs)
    Y_test = test_sampler.data.index.index_to_features(test_sampler.validation_idxs)
    res = {}

    if "dsprites" in train_sampler.data.name:
        Y_train, Y_test = Y_train[:, 0], Y_test[:, 0]
        Y_train_cont, Y_test_cont = Y_train[:, 1:], Y_test[:, 1:]
        lr = LinearRegression().fit(Z_train, Y_train_cont)
        Y_pred_cont = lr.predict(Z_test)
        mse = mean_squared_error(Y_test_cont, Y_pred_cont)
        logger.info("MSE is {}".format(mse))
        res["mse"] = mse
    clf = LogisticRegression(random_state=cfg.seed).fit(Z_train, Y_train)
    Y_pred = clf.predict(Z_test)
    macro_f1 = f1_score(Y_test, Y_pred, average='macro')
    logger.info("Macro f1 is {}".format(macro_f1))
    res["f1"] = [macro_f1]
    df = pd.DataFrame.from_dict(res)
    df.to_csv(cfg.save_file)


if __name__ == "__main__":
    evaluate_on_downstream_tasks()
