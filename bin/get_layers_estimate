#!/usr/bin/env python
import logging
import hydra
import pandas as pd
from hydra.utils import instantiate, call
from omegaconf import OmegaConf
from glob import glob
from vae_ld.data.util import natural_sort, get_unique_samples
import tensorflow as tf
from vae_ld.learning_dynamics.utils import prepare_activations, get_model_epoch
import numpy as np

logger = logging.getLogger("get_layers_estimate")


def compute_estimates(model, model_info, sampler, estimator, name, n_iter, act_fn):
    res = []
    for i in range(0, n_iter):
        X = sampler[i][0]
        X = get_unique_samples(X)

        if (isinstance(X, tuple) and X[0].size == 0) or (not isinstance(X, tuple) and X.size == 0):
            logger.info("The entire dataset used in {} steps. Skipping the remaining steps.".format(i+1))
            break

        _, acts, layers = act_fn(X, None, model=model)
        logger.debug("Batch shape is: {}".format(X[0].shape if isinstance(X, tuple) else X.shape))
        acts = [prepare_activations(act) for act in acts]
        for j, l1 in enumerate(layers):
            logger.info("Iteration {}/{}: computing estimate of layer {}".format(i + 1, n_iter, l1))
            res.append({"estimator": name, "layer": l1, "batch": i,
                        "estimate": estimator.fit_transform(acts[j])})
            logger.debug("Estimate for {} on batch {} using {} = {}".format(l1, i, name, res[-1]["estimate"]))
    df = pd.DataFrame(res)
    for k, v in model_info.items():
        df[k] = v
    return df


@hydra.main(config_path="config", config_name="layers_estimate")
def get_all_ides(cfg):
    logger.info("Experiment config:\n{}".format(OmegaConf.to_yaml(cfg)))

    logger.info("Instantiating estimator")
    estimator = instantiate(cfg.fondue_estimator)

    logger.info("Instantiating {} dataset".format(cfg.dataset.name))
    sampler = instantiate(cfg.sampling)
    model_info = {"model_name": cfg.model_name, "param_name": cfg.param_name,
                  "param_value": cfg.param_value, "model_seed": cfg.model_seed,
                  "seed": cfg.seed, "latent_dim": cfg.latent_dim}
    logger.info("Loading model from {}".format(cfg.model_path))

    files = sorted(glob(cfg.model_path), key=natural_sort)
    if cfg.checkpoint is not None:
        files = np.array(files)
        # Keep only the nth model checkpoints
        files = files[list(cfg.checkpoint)]

    activations_fn = call(cfg.activations.fn, _partial_=True)

    df = None

    for file in files:
        model = tf.keras.models.load_model(file)
        model_info["model_epoch"] = get_model_epoch(file)
        logger.info("Computing estimates")
        df2 = compute_estimates(model, model_info, sampler, estimator, cfg.fondue_type, cfg.n_iter, activations_fn)
        df = pd.concat([df, df2], ignore_index=True) if df is not None else df2
        logger.info("Saving the results to {}".format(cfg.save_file))
        df.to_csv(cfg.save_file, sep="\t")

if __name__ == "__main__":
    get_all_ides()
